# ğŸ“š GIET Study Buddy

> An AI-powered academic assistant built for students of GIET University â€” ask questions, generate exam papers, and contribute to a shared knowledge base.

---
## â— Problem Statement

Students often use generic AI tools to clear academic doubts. However, these tools are not syllabus-aware and do not understand GIET Universityâ€™s semester-wise curriculum. They may provide overly complex explanations, off-syllabus content, or even incorrect and hallucinated answers.

Because of this, students experience confusion instead of clarity. There is currently no dedicated AI system that is aligned with GIETâ€™s subjects, semesters, and academic structure.

A controlled, context-aware, and syllabus-grounded academic assistant is needed to ensure accurate and reliable learning support.

---

## âœ… Our Solution

GIET Study Buddy is a syllabus-aware AI academic assistant designed specifically for GIET University students.

It solves the problem by:

- Using Retrieval-Augmented Generation (RAG) to generate answers grounded in actual GIET syllabus and notes
- Organizing content by semester and subject for structured learning
- Allowing students to generate university-style exam questions
- Enabling community contributions with admin moderation and verification
- Ensuring answers are accurate, context-aware, and classroom-aligned

Instead of being a generic chatbot, GIET Study Buddy acts as a trusted academic companion built specifically for the GIET ecosystem.

---

## âœ¨ Features

- ğŸ¤– **AI Tutor** â€” Ask subject-specific questions and get answers powered by OpenAI, grounded in your actual syllabus via RAG
- ğŸ“ **Exam Question Generator** â€” Generate 10 important university-style questions for any subject and semester
- ğŸ“‚ **Structured Library** â€” Notes and PYQs organized by semester and subject, queryable through the RAG pipeline
- ğŸ™Œ **Community Contributions** â€” Students can upload PDFs, PPTs, and images to grow the knowledge base
- ğŸ›¡ï¸ **Admin Moderation** â€” Uploaded content goes through a verification step before being indexed

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|---|---|
| Frontend | HTML, CSS, Vanilla JavaScript |
| Backend | Python, Flask |
| AI | OpenAI API (GPT) |
| Retrieval | RAG (Retrieval-Augmented Generation) |
| Document Store | Vector store for embedded syllabus & notes |

---

## ğŸ—‚ï¸ Project Structure

```
GDG/
â”œâ”€â”€ frontend/                      # Frontend (HTML, CSS, JS)
â”‚   â”œâ”€â”€ index.html                 # Main app â€” single-page with all sections
â”‚   â”œâ”€â”€ landing.html               # Landing / intro page
â”‚   â”œâ”€â”€ index.css                  # Styles
â”‚   â”œâ”€â”€ app.js                     # Client-side logic & API calls
â”‚   â””â”€â”€ logo.png                   # App logo
â”‚
â”œâ”€â”€ avavilable syllabus/           # Raw syllabus documents by subject/semester
â”œâ”€â”€ GIET Notes/                    # Uploaded and verified student notes
â”œâ”€â”€ __pycache__/                   # Python cache (auto-generated)
â”œâ”€â”€ venv/                          # Python virtual environment
â”‚
â”œâ”€â”€ server.py                      # Flask server â€” main entry point & API routes
â”œâ”€â”€ rag_engine.py                  # RAG pipeline (retrieve + generate answers)
â”œâ”€â”€ retrival_engine.py             # Vector similarity retrieval logic
â”œâ”€â”€ content_classifier.py          # Classifies documents by subject/semester
â”œâ”€â”€ extractor.py                   # Extracts text from PDFs, PPTs, images
â”œâ”€â”€ chunk_documents.py             # Splits documents into chunks for embedding
â”œâ”€â”€ build_index.py                 # Builds the FAISS vector index
â”œâ”€â”€ build_raw_dataset.py           # Prepares raw dataset from source documents
â”œâ”€â”€ list_models.py                 # Lists available OpenAI models
â”œâ”€â”€ stats.py                       # Usage/stats utilities
â”‚
â”œâ”€â”€ faiss_index.index              # FAISS vector index (built from documents)
â”œâ”€â”€ metadata.pkl                   # Metadata store for indexed chunks
â”œâ”€â”€ chunked_documents.json         # Chunked document store
â”œâ”€â”€ classified_documents.json      # Documents classified by subject/semester
â”œâ”€â”€ raw_documents.json             # Raw extracted document data
â”‚
â”œâ”€â”€ rag_test.py                    # Test script for RAG pipeline
â”œâ”€â”€ test_gen.py                    # Test script for question generation
â”œâ”€â”€ test_question.py               # Test script for Q&A
â”œâ”€â”€ test_retrival.py               # Test script for retrieval engine
â”œâ”€â”€ tst.py                         # General test/scratch script
â”‚
â”œâ”€â”€ .env                           # API keys â€” not committed to version control
â”œâ”€â”€ .gitignore                     # Git ignore rules
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # Project documentation
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9+
- OpenAI API key

### Installation

```bash
# Clone the repository
git clone https://github.com/your-username/GIET-Study-Buddy.git
cd GIET-Study-Buddy

# Install Python dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Add your OpenAI API key to .env
```

### Environment Variables

Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=your_openai_api_key_here
FLASK_ENV=development
FLASK_PORT=5000
```

### Running the App

```bash
# Start the Flask backend
python backend/app.py

# Open frontend/index.html in your browser
# or serve it via Flask's static file serving
```

---

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/api/metadata` | Fetch available semesters and subjects |
| `POST` | `/api/ask` | Ask a question (RAG-powered answer) |
| `POST` | `/api/generate-questions` | Generate exam questions for a subject |
| `POST` | `/api/contribute` | Submit a document for verification |

### Example Request â€” Ask a Question

```json
POST /api/ask
{
  "question": "Explain the concept of normalization in DBMS",
  "semester": "Semester 3",
  "subject": "Database Management Systems"
}
```

### Example Response

```json
{
  "answer": "Normalization is the process of organizing a database to reduce redundancy..."
}
```

---

## ğŸ§  How RAG Works

1. **Ingest** â€” Uploaded documents (PDFs, PPTs) are parsed and split into chunks
2. **Embed** â€” Each chunk is converted into a vector embedding using OpenAI's embedding model
3. **Store** â€” Embeddings are stored in a vector store indexed by semester and subject
4. **Retrieve** â€” On a user query, the most relevant chunks are retrieved via similarity search
5. **Generate** â€” The retrieved context is passed to GPT along with the user's question to produce a grounded answer

---

## ğŸ“Œ Status

ğŸš§ **Active Development** â€” Core features are functional. Contribution verification and admin panel are in progress.

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Commit your changes (`git commit -m 'Add your feature'`)
4. Push to the branch (`git push origin feature/your-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ‘¤ Author

Built with â¤ï¸ for GIET University students.
